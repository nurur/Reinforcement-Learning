{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI : Car Racing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Racing Environemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import the library\"\"\"\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"create a simulation environment using make function\"\"\"\n",
    "\"\"\"returns the environment that was passed as parameter\"\"\"\n",
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1037..1307 -> 270-tiles track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"initialize the environemnt using reset method\"\"\"\n",
    "\"\"\"returns an initial observation\"\"\"\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"create the enviroment using render method\"\"\"\n",
    "\"\"\"returns a popup window display of the environment\"\"\"\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(96, 96, 3)\n",
      "state sample : [[[117   9 110]\n",
      "  [136 144  96]\n",
      "  [207 240  14]\n",
      "  ...\n",
      "  [125 196 194]\n",
      "  [110 116 195]\n",
      "  [202   1 242]]\n",
      "\n",
      " [[217 191 176]\n",
      "  [247   8 149]\n",
      "  [107 254 251]\n",
      "  ...\n",
      "  [ 60  77  57]\n",
      "  [ 23 243  57]\n",
      "  [186 185 105]]\n",
      "\n",
      " [[ 35 229  63]\n",
      "  [ 41  54 127]\n",
      "  [ 71 170  14]\n",
      "  ...\n",
      "  [246 231 112]\n",
      "  [ 52 239  80]\n",
      "  [235  77 120]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  6  10 135]\n",
      "  [197 144 231]\n",
      "  [221 233  37]\n",
      "  ...\n",
      "  [169 211 156]\n",
      "  [200  47 224]\n",
      "  [254 159 234]]\n",
      "\n",
      " [[ 19 158  40]\n",
      "  [121  60 231]\n",
      "  [119 194 107]\n",
      "  ...\n",
      "  [248  67 111]\n",
      "  [ 93 125 184]\n",
      "  [ 62 202 137]]\n",
      "\n",
      " [[ 34  93   6]\n",
      "  [194  94 107]\n",
      "  [132 217 194]\n",
      "  ...\n",
      "  [164   4  13]\n",
      "  [218 150 253]\n",
      "  [121 153  69]]]\n"
     ]
    }
   ],
   "source": [
    "print( env.observation_space )\n",
    "#print('state space  :', env.observation_space.n)\n",
    "print('state sample :', env.observation_space.sample() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(3,)\n",
      "action sample : [0.7542727  0.246392   0.86399215]\n"
     ]
    }
   ],
   "source": [
    "print( env.action_space )\n",
    "#print('action space  :', env.action_space.n)\n",
    "print('action sample :', env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Episode finished after 1000 timesteps\n"
     ]
    }
   ],
   "source": [
    "for episode in range(10):\n",
    "    observation = env.reset()\n",
    "    # Render the environment on each step \n",
    "    for t in range(1000):\n",
    "        env.render()\n",
    "        # We choose action by sampling random action from environment's action space. \n",
    "        # Every environment has some action space which contains the all possible valid actions and observations\n",
    "        action = env.action_space.sample()\n",
    "        # Then for each step, we will record the observation, reward, done, info\n",
    "        observation, reward, done, info = env.step(action)\n",
    "    # When done is true, we print the time steps taken for the episode and break the current episode.\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break\n",
    "    print(\"End of episode\", episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
