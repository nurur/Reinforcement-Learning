{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI : Bipedal Walker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"create a simulation environment using make function\"\"\"\n",
    "\"\"\"returns the environment that was passed as parameter\"\"\"\n",
    "env = gym.make('BipedalWalker-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"initialize the environemnt using reset method\"\"\"\n",
    "\"\"\"returns an initial observation\"\"\"\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create the enviroment using render method\"\"\"\n",
    "\"\"\"returns a popup window display of the environment\"\"\"\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( env.observation_space )\n",
    "print('state sample :', env.observation_space.sample() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( env.action_space )\n",
    "print('action sample :', env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(10):\n",
    "    observation = env.reset()\n",
    "    # Render the environment on each step \n",
    "    for t in range(1000):\n",
    "        env.render()\n",
    "        # We choose action by sampling random action from environment's action space. \n",
    "        # Every environment has some action space which contains the all possible valid actions and observations\n",
    "        action = env.action_space.sample()\n",
    "        # Then for each step, we will record the observation, reward, done, info\n",
    "        observation, reward, done, info = env.step(action)\n",
    "    # When done is true, we print the time steps taken for the episode and break the current episode.\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break\n",
    "    print(\"End of episode\", episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
